{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629d6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac45d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[\"SFF\", \"FHF\", \"FGF\"]\n",
    "\n",
    "env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x5\", is_slippery=False, render_mode=\"human\") \n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37dc04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklistedActions = np.empty((env.observation_space.n), dtype=object)\n",
    "\n",
    "for rowIndex, row in enumerate(desc):\n",
    "    for columnIndex, typ in enumerate(row):\n",
    "        blacklist = []\n",
    "        if rowIndex == 0:\n",
    "            blacklist.append(3)\n",
    "        elif rowIndex == len(desc)-1:\n",
    "            blacklist.append(1)\n",
    "        if columnIndex == 0:\n",
    "            blacklist.append(0)\n",
    "        elif columnIndex == len(row)-1:\n",
    "            blacklist.append(2)\n",
    "        blacklistedActions[(len(row)*rowIndex)+(columnIndex)] = blacklist\n",
    "\n",
    "def is_valid_action(state, action):\n",
    "    stateBlacklist = blacklistedActions[state]\n",
    "    \n",
    "    if action in stateBlacklist:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "698dabd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hit gift! At Episode: 4\n",
      "\n",
      "[[-10.    0.    0.  -10. ]\n",
      " [  0.   -0.1   0.  -10. ]\n",
      " [  0.    0.  -10.  -10. ]\n",
      " [-10.    0.   -0.1   0. ]\n",
      " [  0.    0.    0.    0. ]\n",
      " [ -0.1   0.  -10.    0. ]\n",
      " [-10.  -10.    0.    0. ]\n",
      " [  0.  -10.    0.    0. ]\n",
      " [  0.1 -10.  -10.    0. ]]\n",
      "\n",
      "States / path: \n",
      "[0, 1, 0, 3, 6, 3, 0, 3, 6, 3, 0, 3, 0, 3, 0, 1, 0, 1, 2, 1, 2, 5, 8, 7]\n",
      "\n",
      "Elapsed time: 9.757920265197754 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 5\n",
      "\n",
      "[[-1.0e+01  0.0e+00  0.0e+00 -1.0e+01]\n",
      " [ 0.0e+00 -1.0e-01  0.0e+00 -1.0e+01]\n",
      " [ 0.0e+00  0.0e+00 -1.0e+01 -1.0e+01]\n",
      " [-1.0e+01  0.0e+00 -1.0e-01  0.0e+00]\n",
      " [ 0.0e+00  0.0e+00  0.0e+00  0.0e+00]\n",
      " [-1.0e-01  9.0e-03 -1.0e+01  0.0e+00]\n",
      " [-1.0e+01 -1.0e+01  0.0e+00  0.0e+00]\n",
      " [ 0.0e+00 -1.0e+01  0.0e+00  0.0e+00]\n",
      " [ 1.9e-01 -1.0e+01 -1.0e+01  0.0e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 1, 0, 1, 2, 5, 2, 1, 2, 1, 2, 5, 8, 7]\n",
      "\n",
      "Elapsed time: 13.27092456817627 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 6\n",
      "\n",
      "[[-1.0e+01  0.0e+00  0.0e+00 -1.0e+01]\n",
      " [ 0.0e+00 -1.0e-01  0.0e+00 -1.0e+01]\n",
      " [ 0.0e+00  0.0e+00 -1.0e+01 -1.0e+01]\n",
      " [-1.0e+01  0.0e+00 -1.0e-01  0.0e+00]\n",
      " [ 0.0e+00  0.0e+00  0.0e+00  0.0e+00]\n",
      " [-1.0e-01  9.0e-03 -1.0e+01  0.0e+00]\n",
      " [-1.0e+01 -1.0e+01  1.0e-01  0.0e+00]\n",
      " [ 0.0e+00 -1.0e+01  0.0e+00  0.0e+00]\n",
      " [ 1.9e-01 -1.0e+01 -1.0e+01  0.0e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 1, 0, 3, 6, 3, 0, 1, 2, 1, 0, 3, 6, 3, 6, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 17.788976192474365 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 7\n",
      "\n",
      "[[-1.0e+01  0.0e+00  0.0e+00 -1.0e+01]\n",
      " [ 0.0e+00 -1.0e-01  0.0e+00 -1.0e+01]\n",
      " [ 0.0e+00  0.0e+00 -1.0e+01 -1.0e+01]\n",
      " [-1.0e+01  9.0e-03 -1.0e-01  0.0e+00]\n",
      " [ 0.0e+00  0.0e+00  0.0e+00  0.0e+00]\n",
      " [-1.0e-01  9.0e-03 -1.0e+01  0.0e+00]\n",
      " [-1.0e+01 -1.0e+01  1.9e-01  0.0e+00]\n",
      " [ 0.0e+00 -1.0e+01  0.0e+00  0.0e+00]\n",
      " [ 1.9e-01 -1.0e+01 -1.0e+01  0.0e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 19.29304814338684 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 8\n",
      "\n",
      "[[-1.00e+01  0.00e+00  0.00e+00 -1.00e+01]\n",
      " [ 0.00e+00 -1.00e-01  0.00e+00 -1.00e+01]\n",
      " [ 0.00e+00  8.10e-04 -1.00e+01 -1.00e+01]\n",
      " [-1.00e+01  9.00e-03 -1.00e-01  0.00e+00]\n",
      " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
      " [-1.00e-01  2.52e-02 -1.00e+01  0.00e+00]\n",
      " [-1.00e+01 -1.00e+01  1.90e-01  0.00e+00]\n",
      " [ 0.00e+00 -1.00e+01  0.00e+00  0.00e+00]\n",
      " [ 2.71e-01 -1.00e+01 -1.00e+01  0.00e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 1, 2, 1, 2, 5, 8, 7]\n",
      "\n",
      "Elapsed time: 21.30007004737854 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 10\n",
      "\n",
      "[[-1.000e+01  1.539e-03  0.000e+00 -1.000e+01]\n",
      " [ 0.000e+00 -1.000e-01  0.000e+00 -1.000e+01]\n",
      " [ 0.000e+00  8.100e-04 -1.000e+01 -1.000e+01]\n",
      " [-1.000e+01  2.520e-02 -1.900e-01  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00]\n",
      " [-1.000e-01  2.520e-02 -1.000e+01  0.000e+00]\n",
      " [-1.000e+01 -1.000e+01  2.710e-01  0.000e+00]\n",
      " [ 0.000e+00 -1.000e+01  0.000e+00  0.000e+00]\n",
      " [ 2.710e-01 -1.000e+01 -1.000e+01  0.000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 24.06110453605652 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 11\n",
      "\n",
      "[[-1.0000e+01  3.6531e-03  0.0000e+00 -1.0000e+01]\n",
      " [ 0.0000e+00 -1.0000e-01  0.0000e+00 -1.0000e+01]\n",
      " [ 0.0000e+00  8.1000e-04 -1.0000e+01 -1.0000e+01]\n",
      " [-1.0000e+01  4.7070e-02 -1.9000e-01  0.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [-1.0000e-01  2.5200e-02 -1.0000e+01  0.0000e+00]\n",
      " [-1.0000e+01 -1.0000e+01  3.4390e-01  0.0000e+00]\n",
      " [ 0.0000e+00 -1.0000e+01  0.0000e+00  0.0000e+00]\n",
      " [ 2.7100e-01 -1.0000e+01 -1.0000e+01  0.0000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 25.06311273574829 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 12\n",
      "\n",
      "[[-1.00000e+01  7.52409e-03  0.00000e+00 -1.00000e+01]\n",
      " [ 0.00000e+00 -1.00000e-01  0.00000e+00 -1.00000e+01]\n",
      " [ 0.00000e+00  8.10000e-04 -1.00000e+01 -1.00000e+01]\n",
      " [-1.00000e+01  7.33140e-02 -1.90000e-01  0.00000e+00]\n",
      " [ 0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00]\n",
      " [-1.00000e-01  2.52000e-02 -1.00000e+01  0.00000e+00]\n",
      " [-1.00000e+01 -1.00000e+01  4.09510e-01  0.00000e+00]\n",
      " [ 0.00000e+00 -1.00000e+01  0.00000e+00  0.00000e+00]\n",
      " [ 2.71000e-01 -1.00000e+01 -1.00000e+01  0.00000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 26.066155195236206 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 13\n",
      "\n",
      "[[-1.0000000e+01  1.3369941e-02  0.0000000e+00 -1.0000000e+01]\n",
      " [ 0.0000000e+00 -1.0000000e-01  0.0000000e+00 -1.0000000e+01]\n",
      " [ 0.0000000e+00  8.1000000e-04 -1.0000000e+01 -1.0000000e+01]\n",
      " [-1.0000000e+01  1.0283850e-01 -1.9000000e-01  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-1.0000000e-01  2.5200000e-02 -1.0000000e+01  0.0000000e+00]\n",
      " [-1.0000000e+01 -1.0000000e+01  4.6855900e-01  0.0000000e+00]\n",
      " [ 0.0000000e+00 -1.0000000e+01  0.0000000e+00  0.0000000e+00]\n",
      " [ 2.7100000e-01 -1.0000000e+01 -1.0000000e+01  0.0000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 27.069319486618042 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 14\n",
      "\n",
      "[[-1.00000000e+01  2.12884119e-02  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00 -1.00000000e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  8.10000000e-04 -1.00000000e+01 -1.00000000e+01]\n",
      " [-1.00000000e+01  1.34724960e-01 -1.90000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  2.52000000e-02 -1.00000000e+01  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01  5.21703100e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.71000000e-01 -1.00000000e+01 -1.00000000e+01  0.00000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 28.07136058807373 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 15\n",
      "\n",
      "[[-1.00000000e+01  3.12848171e-02  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00 -1.00000000e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  8.10000000e-04 -1.00000000e+01 -1.00000000e+01]\n",
      " [-1.00000000e+01  1.68205743e-01 -1.90000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  2.52000000e-02 -1.00000000e+01  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01  5.69532790e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.71000000e-01 -1.00000000e+01 -1.00000000e+01  0.00000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 29.073381662368774 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 16\n",
      "\n",
      "[[-1.00000000e+01  4.32948523e-02  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00 -1.00000000e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  8.10000000e-04 -1.00000000e+01 -1.00000000e+01]\n",
      " [-1.00000000e+01  2.02643120e-01 -1.90000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  2.52000000e-02 -1.00000000e+01  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01  6.12579511e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.71000000e-01 -1.00000000e+01 -1.00000000e+01  0.00000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 30.075355529785156 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 17\n",
      "\n",
      "[[-1.00000000e+01  5.72032478e-02  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00 -1.00000000e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  8.10000000e-04 -1.00000000e+01 -1.00000000e+01]\n",
      " [-1.00000000e+01  2.37510964e-01 -1.90000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  2.52000000e-02 -1.00000000e+01  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01  6.51321560e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.71000000e-01 -1.00000000e+01 -1.00000000e+01  0.00000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 31.07936668395996 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 18\n",
      "\n",
      "[[-1.00000000e+01  7.28589098e-02  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00 -1.00000000e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  8.10000000e-04 -1.00000000e+01 -1.00000000e+01]\n",
      " [-1.00000000e+01  2.72378808e-01 -1.90000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  2.52000000e-02 -1.00000000e+01  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01  6.86189404e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.71000000e-01 -1.00000000e+01 -1.00000000e+01  0.00000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 32.08338165283203 seconds\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hit gift! At Episode: 19\n",
      "\n",
      "[[-1.00000000e+01  9.00871115e-02  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00 -1.00000000e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  8.10000000e-04 -1.00000000e+01 -1.00000000e+01]\n",
      " [-1.00000000e+01  3.06897973e-01 -1.90000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  2.52000000e-02 -1.00000000e+01  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01  7.17570464e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.71000000e-01 -1.00000000e+01 -1.00000000e+01  0.00000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 33.085387229919434 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hit gift! At Episode: 20\n",
      "\n",
      "[[-1.00000000e+01  1.08699218e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00 -1.00000000e-01  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  8.10000000e-04 -1.00000000e+01 -1.00000000e+01]\n",
      " [-1.00000000e+01  3.40789518e-01 -1.90000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  2.52000000e-02 -1.00000000e+01  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01  7.45813417e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.71000000e-01 -1.00000000e+01 -1.00000000e+01  0.00000000e+00]]\n",
      "\n",
      "States / path: \n",
      "[0, 3, 6, 7]\n",
      "\n",
      "Elapsed time: 34.088401556015015 seconds\n",
      "\n",
      "\n",
      "Optimal policy:\n",
      "[1 0 1 1 0 1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "gamma = 0.9  # Discount factor\n",
    "alpha = 0.1  # Learning rate\n",
    "epsilon = 0.05  # Epsilon-greedy parameter\n",
    "num_episodes = 20\n",
    "\n",
    "# Initialize Q-values\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "Q = np.zeros((num_states, num_actions))\n",
    "\n",
    "stateI = 0\n",
    "for state in Q:\n",
    "    for action in blacklistedActions[stateI]:\n",
    "        Q[stateI][action] = -10\n",
    "    stateI+=1\n",
    "\n",
    "# Q-learning algorithm\n",
    "start_time = time.time()\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    \n",
    "    states = []\n",
    "    \n",
    "    while not done:\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.rand() < epsilon:\n",
    "            actionLoop = True\n",
    "            while actionLoop:\n",
    "                action = env.action_space.sample()  # Random action\n",
    "                if is_valid_action(state, action):\n",
    "                    actionLoop = False\n",
    "        else:\n",
    "            ind = 0\n",
    "            maxIndices = []\n",
    "            maxNum = -1\n",
    "            for num in Q[state]:\n",
    "                if num > maxNum:\n",
    "                    maxIndices = [ind]\n",
    "                    maxNum = num\n",
    "                elif num == maxNum:\n",
    "                    maxIndices.append(ind)\n",
    "                ind += 1\n",
    "                \n",
    "            maxInd = -1\n",
    "            if len(maxIndices) >= 1:\n",
    "                maxInd = maxIndices[random.randint(0, len(maxIndices) - 1)]\n",
    "                \n",
    "            if maxInd== -1:\n",
    "                maxInd = env.action_space.sample()\n",
    "            action = maxInd  # Greedy action\n",
    "        \n",
    "        # Take action and observe next state and reward\n",
    "        states.append(state)\n",
    "        step = env.step(action)\n",
    "        next_state = step[0]\n",
    "        reward = step[1]\n",
    "        done = step[2]\n",
    "        \n",
    "        if reward == 0 and done:\n",
    "            reward = -1\n",
    "        elif next_state == state:\n",
    "            reward = -1\n",
    "            print(\"hit wall?\")\n",
    "        \n",
    "        # Update Q-value\n",
    "        Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state, :]) - Q[state, action])\n",
    "        \n",
    "        if reward == 1:\n",
    "            print(\"\\n\\nHit gift! At Episode: \"+str(episode +1)+\"\\n\")\n",
    "            print(Q)\n",
    "            states.append(next_state)\n",
    "            print(\"\\nStates / path: \")\n",
    "            print(states)\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(\"\\nElapsed time:\", elapsed_time, \"seconds\\n\\n\")\n",
    "        \n",
    "        # Move to next state\n",
    "        state = next_state\n",
    "\n",
    "# Optimal policy\n",
    "optimal_policy = np.argmax(Q, axis=1)\n",
    "\n",
    "print(\"Optimal policy:\")\n",
    "print(optimal_policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6e831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
